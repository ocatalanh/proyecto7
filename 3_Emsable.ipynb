{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento muestreados desde el archivo pickle\n",
    "with open('datos_entrenamiento_muestreados.pickle', 'rb') as f:\n",
    "    X_train_resampled, y_train_resampled = pickle.load(f)\n",
    "\n",
    "# Cargar el modelo entrenado desde el archivo pickle\n",
    "with open('mejor_rf_modelo.pickle', 'rb') as f:\n",
    "    best_rf_classifier = pickle.load(f)\n",
    "\n",
    "# Cargar las variables desde el archivo pickle\n",
    "with open('datos_split_procesados.pickle', 'rb') as f:\n",
    "    X_train_pca, X_test_pca, y_train, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de Bagging: 0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Cargar el modelo entrenado desde el archivo pickle\n",
    "with open('mejor_rf_modelo.pickle', 'rb') as f:\n",
    "    best_rf_classifier = pickle.load(f)\n",
    "\n",
    "# Número de modelos a crear (puedes ajustar este valor según tus necesidades)\n",
    "num_modelos = 27\n",
    "\n",
    "# Crear un clasificador de Bagging con el modelo RandomForestClassifier como estimador base\n",
    "bagging_classifier = BaggingClassifier(estimator=best_rf_classifier, \n",
    "                                       n_estimators=num_modelos, \n",
    "                                       random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de Bagging\n",
    "bagging_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calcular la precisión del clasificador de Bagging en el conjunto de prueba\n",
    "bagging_accuracy = bagging_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de Bagging:\", bagging_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de AdaBoost: 0.574468085106383\n",
      "Informe de Clasificación (AdaBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.65      0.81      0.72        32\n",
      "           2       0.14      0.09      0.11        11\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.26      0.30      0.28        47\n",
      "weighted avg       0.48      0.57      0.52        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargar el modelo entrenado desde el archivo pickle\n",
    "with open('mejor_rf_modelo.pickle', 'rb') as f:\n",
    "    best_rf_classifier = pickle.load(f)\n",
    "\n",
    "# Crear un clasificador de AdaBoost con el modelo RandomForestClassifier como base\n",
    "ada_classifier = AdaBoostClassifier(estimator=best_rf_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de AdaBoost\n",
    "ada_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_ada = ada_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de AdaBoost\n",
    "ada_accuracy = ada_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de AdaBoost:\", ada_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (AdaBoost):\\n\", classification_report(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de Gradient Boosting: 0.5106382978723404\n",
      "Informe de Clasificación (Gradient Boosting):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.68      0.59      0.63        32\n",
      "           2       0.26      0.45      0.33        11\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.31      0.35      0.32        47\n",
      "weighted avg       0.52      0.51      0.51        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Crear un clasificador de Gradient Boosting\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de Gradient Boosting\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_gb = gb_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de Gradient Boosting\n",
    "gb_accuracy = gb_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de Gradient Boosting:\", gb_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (Gradient Boosting):\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de XGBoost: 0.5957446808510638\n",
      "Informe de Clasificación (XGBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.71      0.75      0.73        32\n",
      "           2       0.33      0.36      0.35        11\n",
      "\n",
      "    accuracy                           0.60        47\n",
      "   macro avg       0.35      0.37      0.36        47\n",
      "weighted avg       0.56      0.60      0.58        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Crear un clasificador de XGBoost\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de XGBoost\n",
    "xgb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_xgb = xgb_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de XGBoost\n",
    "xgb_accuracy = xgb_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de XGBoost:\", xgb_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (XGBoost):\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de validación cruzada: [0.75384615 0.828125   0.8125     0.875      0.890625  ]\n",
      "Precisión media de validación cruzada: 0.8320192307692308\n"
     ]
    }
   ],
   "source": [
    "# Validación cruzada con el modelo Random Forest original\n",
    "cv_scores = cross_val_score(best_rf_classifier, X_train_resampled, y_train_resampled, cv=5)\n",
    "print(\"Puntuaciones de validación cruzada:\", cv_scores)\n",
    "print(\"Precisión media de validación cruzada:\", np.mean(cv_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
