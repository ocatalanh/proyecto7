{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pickle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento muestreados desde el archivo pickle\n",
    "with open(r'C:\\Users\\ocata\\OneDrive\\Desktop\\Proyecto7_DS\\data\\processed\\datos_entrenamiento_muestreados.pkl', 'rb') as f:\n",
    "    X_train_resampled, y_train_resampled = pickle.load(f)\n",
    "\n",
    "# Cargar el modelo entrenado desde el archivo pickle\n",
    "with open(R'C:\\Users\\ocata\\OneDrive\\Desktop\\Proyecto7_DS\\models\\mejor_rf_modelo.pkl', 'rb') as f:\n",
    "    best_rf_classifier = pickle.load(f)\n",
    "\n",
    "# Cargar las variables desde el archivo pickle\n",
    "with open(R'C:\\Users\\ocata\\OneDrive\\Desktop\\Proyecto7_DS\\data\\processed\\datos_split_procesados.pkl', 'rb') as f:\n",
    "    X_train_pca, X_test_pca, y_train, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizamos la tecnica de BaggingClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de Bagging: 0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Número de modelos a crear (puedes ajustar este valor según tus necesidades)\n",
    "num_modelos = 27\n",
    "\n",
    "# Crear un clasificador de Bagging con el modelo RandomForestClassifier como estimador base\n",
    "bagging_classifier = BaggingClassifier(estimator=best_rf_classifier, \n",
    "                                       n_estimators=num_modelos, \n",
    "                                       random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de Bagging\n",
    "bagging_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calcular la precisión del clasificador de Bagging en el conjunto de prueba\n",
    "bagging_accuracy = bagging_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de Bagging:\", bagging_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utillizamos la tecnica de AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de AdaBoost: 0.6595744680851063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación (AdaBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.69      0.91      0.78        32\n",
      "           2       0.40      0.18      0.25        11\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.36      0.36      0.34        47\n",
      "weighted avg       0.56      0.66      0.59        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear un clasificador de AdaBoost con el modelo RandomForestClassifier como base\n",
    "ada_classifier = AdaBoostClassifier(estimator=best_rf_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de AdaBoost\n",
    "ada_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_ada = ada_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de AdaBoost\n",
    "ada_accuracy = ada_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de AdaBoost:\", ada_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (AdaBoost):\\n\", classification_report(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizamos la tecnica de GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de Gradient Boosting: 0.48936170212765956\n",
      "Informe de Clasificación (Gradient Boosting):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.63      0.59      0.61        32\n",
      "           2       0.19      0.27      0.22        11\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.61      0.37      0.41        47\n",
      "weighted avg       0.56      0.49      0.50        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear un clasificador de Gradient Boosting\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de Gradient Boosting\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_gb = gb_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de Gradient Boosting\n",
    "gb_accuracy = gb_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de Gradient Boosting:\", gb_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (Gradient Boosting):\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizamos la tecnica de XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador de XGBoost: 0.6382978723404256\n",
      "Informe de Clasificación (XGBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.72      0.81      0.76        32\n",
      "           2       0.36      0.36      0.36        11\n",
      "\n",
      "    accuracy                           0.64        47\n",
      "   macro avg       0.36      0.39      0.38        47\n",
      "weighted avg       0.58      0.64      0.61        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ocata\\miniconda3\\envs\\proyecto7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Crear un clasificador de XGBoost\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el clasificador de XGBoost\n",
    "xgb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_xgb = xgb_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calcular la precisión del clasificador de XGBoost\n",
    "xgb_accuracy = xgb_classifier.score(X_test_pca, y_test)\n",
    "print(\"Precisión del clasificador de XGBoost:\", xgb_accuracy)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Informe de Clasificación (XGBoost):\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizamos una validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de validación cruzada: [0.75384615 0.84375    0.78125    0.875      0.859375  ]\n",
      "Precisión media de validación cruzada: 0.8226442307692308\n"
     ]
    }
   ],
   "source": [
    "# Validación cruzada con el modelo Random Forest original\n",
    "cv_scores = cross_val_score(best_rf_classifier, X_train_resampled, y_train_resampled, cv=5)\n",
    "print(\"Puntuaciones de validación cruzada:\", cv_scores)\n",
    "print(\"Precisión media de validación cruzada:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna de las tecnicas de emsabling arrojó mejores resultados para el modelo. Por otro lado al realizar una validación cruzada tenemos un puntaje del 82% lo cual da cuenta de un modelo de bastante robustes, quedandonos con este modelo para producción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
